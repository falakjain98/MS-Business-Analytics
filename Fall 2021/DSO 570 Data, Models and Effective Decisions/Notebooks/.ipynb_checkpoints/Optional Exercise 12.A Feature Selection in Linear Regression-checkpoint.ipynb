{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdbe2b0",
   "metadata": {},
   "source": [
    "## Optional Exercise 12.A: Feature Selection in Linear Regression\n",
    "\n",
    "A challenge in predictive analytics is to select a few good features out of many thousands of possibilities, so that a linear regression model estimated using these few features still has good predictive power. In this exercise, you will implement a reusable tool that solves this problem using mixed integer programming.\n",
    "\n",
    "The input file is of Excel format and has one sheet. Each row represents an observation. The first column corresponds to the dependent variable the user wishes to predict. Each following column corresponds to a feature that may be used for prediction. The name of the dependent variable as well as the features are given as the first row.\n",
    "\n",
    "![Sample input for 12.A](12-regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1e009",
   "metadata": {},
   "source": [
    "You should implements the following MIP formulation.\n",
    "\n",
    "**Data:**\n",
    "\n",
    "- $I$: the set of rows (`range(5)` in the example above, but should be inferred from the data).\n",
    "- $J$: the set of features (\"X1\", \"X2\", $\\cdots$, \"X8\" in the example above, but should be inferred from the data).\n",
    "- $y_i$: the value of the independent variable in row $i$.\n",
    "- $x_{ij}$: the value of feature $j$ in row $i$. \n",
    "- $k$: the maximum number of features used.\n",
    "- $M$: a big constant.\n",
    "\n",
    "**Decision Variables:**\n",
    "\n",
    "- $\\alpha$: the coefficient of the constant term. (Continuous)\n",
    "- $\\beta_j$: the coefficient for feature $j$. (Continuous)\n",
    "- $p_i$: the predicted value for observation $i$. (Continuous)\n",
    "- $z_j$: whether to use feature $j$. (Binary)\n",
    "\n",
    "**Objective and Constraints:**\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\text{Minimize} && \\sum_{i \\in I} (y_i - p_i)^2 \\\\\n",
    "\\text{s.t} \\\\\n",
    "\\text{(Linear prediction)} && p_i &= \\alpha + \\sum_{j \\in J}x_{ij} \\beta_j && \\text{for each row $i\\in I$.} \\\\\n",
    "\\text{(Big M)} && -Mz_j \\le \\beta_j &\\le Mz_j && \\text{for each feature $j \\in J$.} \\\\\n",
    "\\text{(Using few features)} && \\sum_{j \\in J}z_j &\\le k\n",
    "\\end{aligned}$$\n",
    "\n",
    "**Note that the variables $\\alpha$, $\\beta_j$ and $p_i$ are NOT constrained to be non-negative.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca148a61",
   "metadata": {},
   "source": [
    "**Write a function called \"regress\" to implement the above MIP with three input parameters: **\n",
    "\n",
    "- inputFile: the path to an input file of the following format. \n",
    "- k: the value of the parameter $k$ (see list of data variables above).\n",
    "- M: the value of the parameter $M$ (see list of data variables above).\n",
    "\n",
    "**The function should return a pandas Series object with at most k+1 elements. The first entry has index \"Constant\" and the value corresponds to the optimal value of $\\alpha$. For the subsequent elements, the index corresponds to the name of the features used, and the value correspond to the estimated coefficient $\\beta_j$. Only the non-zero coefficients $\\beta_j$ should be included.** See below for the Series returned using the input file above, and $k=2$, $M=100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f12633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Constant    4.084086\n",
       "X3          2.051074\n",
       "X5          2.969166\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test code\n",
    "coefficients=regress('12-regression-input.xlsx',2,100)\n",
    "coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab3c46c",
   "metadata": {},
   "source": [
    "**Write your function below. You must import all packages needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "715f6fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final code\n",
    "# Write your final code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gurobipy import Model, GRB\n",
    "\n",
    "def regress(inputFile,k,M):\n",
    "    reg = pd.read_excel(inputFile, sheet_name = \"Sheet1\")\n",
    "    I = range(len(reg))\n",
    "    J = list(reg.columns)\n",
    "    J.remove('Y')\n",
    "    mod = Model()\n",
    "    alpha = mod.addVar(vtype = GRB.CONTINUOUS,name = 'alpha')\n",
    "    beta = mod.addVars(J,vtype = GRB.CONTINUOUS,name = 'beta')\n",
    "    p = mod.addVars(I,vtype = GRB.CONTINUOUS,name = 'p')\n",
    "    z = mod.addVars(J,vtype = GRB.BINARY,name = 'z')\n",
    "    mod.setObjective(sum((reg['Y'][i]-p[i])**2 for i in I), sense = GRB.MINIMIZE)\n",
    "    # Linear Prediction\n",
    "    for i in I:\n",
    "        mod.addConstr(p[i] == alpha + sum(reg.loc[i,j]*beta[j] for j in J),name='Linear Prediction')\n",
    "    # Big M\n",
    "    for j in J:\n",
    "        mod.addConstr(beta[j]<=M*z[j],name='Big M 1')\n",
    "        mod.addConstr(beta[j]>=-M*z[j],name='Big M 2')\n",
    "    # Using Few Features\n",
    "    mod.addConstr(sum(z[j] for j in J)<=k,name='Using few features')\n",
    "    mod.setParam(\"OutputFlag\", False)\n",
    "    mod.setParam('MIPGap',1e-6)\n",
    "    mod.optimize()\n",
    "    output = {'Constant':alpha.x}\n",
    "    for j in J:\n",
    "        if z[j].x > 0:\n",
    "            output[j] = beta[j].x\n",
    "    print(pd.Series(output))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
